{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import learning_curve,validation_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score,auc,roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier,callback\n",
    "from catboost import Pool,metrics,cv,MetricVisualizer\n",
    "from catboost.utils import get_roc_curve,select_threshold,get_fpr_curve,get_fnr_curve\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(data):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = data.memory_usage().sum() \n",
    "    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "        else:\n",
    "            data[col] = data[col].astype('category')\n",
    "    end_mem = data.memory_usage().sum() \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(pd.read_csv( './data/train.csv',encoding='utf-8'))\n",
    "test_df = reduce_mem_usage(pd.read_csv( './data/test.csv',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./user_recommend/train_feature3.csv')\n",
    "test_data = pd.read_csv('./user_recommend/test_feature3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>first_year</th>\n",
       "      <th>last_year</th>\n",
       "      <th>session_count</th>\n",
       "      <th>active_days</th>\n",
       "      <th>dif_days_total</th>\n",
       "      <th>dif_days_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>month_11.0_count</th>\n",
       "      <th>month_12.0_count</th>\n",
       "      <th>dayofweek_0.0_count</th>\n",
       "      <th>dayofweek_1.0_count</th>\n",
       "      <th>dayofweek_2.0_count</th>\n",
       "      <th>dayofweek_3.0_count</th>\n",
       "      <th>dayofweek_4.0_count</th>\n",
       "      <th>dayofweek_5.0_count</th>\n",
       "      <th>dayofweek_6.0_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>249.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>20</td>\n",
       "      <td>337.0</td>\n",
       "      <td>16.84</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>349.0</td>\n",
       "      <td>31.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209465</th>\n",
       "      <td>7</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209466</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209467</th>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>214.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209468</th>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>22</td>\n",
       "      <td>148</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209469</th>\n",
       "      <td>11</td>\n",
       "      <td>258</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>317.0</td>\n",
       "      <td>63.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209470 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand  model  province  city  first_year  last_year  session_count  \\\n",
       "0           0      0         0     0           1          0             30   \n",
       "1           1      1         1     1          -1         -1             -1   \n",
       "2           2      2         2     2           1          0             61   \n",
       "3           3      3         3     3           0          0              2   \n",
       "4           3      4         4     4           1          0             50   \n",
       "...       ...    ...       ...   ...         ...        ...            ...   \n",
       "209465      7    285         7   250           1          1              4   \n",
       "209466      3     28        15   223           0          0              2   \n",
       "209467      4    122        24    57           1          0              6   \n",
       "209468      3    233        22   148           4          4             54   \n",
       "209469     11    258        18    42           1          0              8   \n",
       "\n",
       "        active_days  dif_days_total  dif_days_avg  ...  month_11.0_count  \\\n",
       "0                11           249.0         22.64  ...               1.0   \n",
       "1                -1            -1.0         -1.00  ...               0.0   \n",
       "2                20           337.0         16.84  ...               5.0   \n",
       "3                 1             0.0          0.00  ...               0.0   \n",
       "4                11           349.0         31.73  ...               0.0   \n",
       "...             ...             ...           ...  ...               ...   \n",
       "209465            1             0.0          0.00  ...               0.0   \n",
       "209466            1             0.0          0.00  ...               0.0   \n",
       "209467            2           214.0        107.00  ...               0.0   \n",
       "209468            2            25.0         12.50  ...               0.0   \n",
       "209469            5           317.0         63.40  ...               0.0   \n",
       "\n",
       "        month_12.0_count  dayofweek_0.0_count  dayofweek_1.0_count  \\\n",
       "0                    5.0                  4.0                  8.0   \n",
       "1                    0.0                  0.0                  0.0   \n",
       "2                   10.0                 10.0                 16.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                 16.0                  2.0   \n",
       "...                  ...                  ...                  ...   \n",
       "209465               0.0                  4.0                  0.0   \n",
       "209466               0.0                  0.0                  0.0   \n",
       "209467               0.0                  2.0                  0.0   \n",
       "209468               0.0                 42.0                  0.0   \n",
       "209469               0.0                  3.0                  0.0   \n",
       "\n",
       "        dayofweek_2.0_count  dayofweek_3.0_count  dayofweek_4.0_count  \\\n",
       "0                       3.0                  0.0                  1.0   \n",
       "1                       0.0                  0.0                  0.0   \n",
       "2                      19.0                  8.0                  2.0   \n",
       "3                       0.0                  0.0                  0.0   \n",
       "4                       0.0                  2.0                 22.0   \n",
       "...                     ...                  ...                  ...   \n",
       "209465                  0.0                  0.0                  0.0   \n",
       "209466                  0.0                  0.0                  2.0   \n",
       "209467                  0.0                  0.0                  4.0   \n",
       "209468                  0.0                  0.0                 12.0   \n",
       "209469                  5.0                  0.0                  0.0   \n",
       "\n",
       "        dayofweek_5.0_count  dayofweek_6.0_count  label  \n",
       "0                       1.0                 13.0    0.0  \n",
       "1                       0.0                  0.0    0.0  \n",
       "2                       0.0                  6.0    0.0  \n",
       "3                       2.0                  0.0    1.0  \n",
       "4                       0.0                  8.0    0.0  \n",
       "...                     ...                  ...    ...  \n",
       "209465                  0.0                  0.0    0.0  \n",
       "209466                  0.0                  0.0    0.0  \n",
       "209467                  0.0                  0.0    0.0  \n",
       "209468                  0.0                  0.0    0.0  \n",
       "209469                  0.0                  0.0    0.0  \n",
       "\n",
       "[209470 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brand', 'model', 'province', 'city', 'first_year', 'last_year',\n",
       "       'session_count', 'active_days', 'dif_days_total', 'dif_days_avg',\n",
       "       'day_sessions_avg', '2023_session_count', '2023_active_days',\n",
       "       '2023_recency', '2023_dif_days_total', '2023_dif_days_avg',\n",
       "       '2023_day_sessions_avg', 'year_2009.0_count', 'year_2010.0_count',\n",
       "       'year_2015.0_count', 'year_2017.0_count', 'year_2018.0_count',\n",
       "       'year_2019.0_count', 'year_2020.0_count', 'year_2021.0_count',\n",
       "       'year_2022.0_count', 'year_2023.0_count', 'month_1.0_count',\n",
       "       'month_2.0_count', 'month_3.0_count', 'month_4.0_count',\n",
       "       'month_5.0_count', 'month_6.0_count', 'month_7.0_count',\n",
       "       'month_8.0_count', 'month_9.0_count', 'month_10.0_count',\n",
       "       'month_11.0_count', 'month_12.0_count', 'dayofweek_0.0_count',\n",
       "       'dayofweek_1.0_count', 'dayofweek_2.0_count', 'dayofweek_3.0_count',\n",
       "       'dayofweek_4.0_count', 'dayofweek_5.0_count', 'dayofweek_6.0_count',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>first_year</th>\n",
       "      <th>last_year</th>\n",
       "      <th>session_count</th>\n",
       "      <th>active_days</th>\n",
       "      <th>dif_days_total</th>\n",
       "      <th>dif_days_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>month_10.0_count</th>\n",
       "      <th>month_11.0_count</th>\n",
       "      <th>month_12.0_count</th>\n",
       "      <th>dayofweek_0.0_count</th>\n",
       "      <th>dayofweek_1.0_count</th>\n",
       "      <th>dayofweek_2.0_count</th>\n",
       "      <th>dayofweek_3.0_count</th>\n",
       "      <th>dayofweek_4.0_count</th>\n",
       "      <th>dayofweek_5.0_count</th>\n",
       "      <th>dayofweek_6.0_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>20</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>221.0</td>\n",
       "      <td>11.63</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>828</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>223</td>\n",
       "      <td>21</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>253.0</td>\n",
       "      <td>84.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "      <td>18</td>\n",
       "      <td>102</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490525</th>\n",
       "      <td>340</td>\n",
       "      <td>1996</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490526</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490527</th>\n",
       "      <td>2</td>\n",
       "      <td>254</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490528</th>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>254.0</td>\n",
       "      <td>16.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490529</th>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>26.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490530 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand  model  province  city  first_year  last_year  session_count  \\\n",
       "0           2    103        24   136           1          1              2   \n",
       "1           0    283        20   227           1          0             48   \n",
       "2          11    828         4    17          -1         -1             -1   \n",
       "3           3    223        21    84           1          0             10   \n",
       "4           0    385        18   102          -1         -1             -1   \n",
       "...       ...    ...       ...   ...         ...        ...            ...   \n",
       "490525    340   1996         5     5          -1         -1             -1   \n",
       "490526      3     34         5    56           1          1              1   \n",
       "490527      2    254        30   300           1          1              1   \n",
       "490528      3    121        29    98           1          0             39   \n",
       "490529     11     49         2    55           1          0             16   \n",
       "\n",
       "        active_days  dif_days_total  dif_days_avg  ...  month_10.0_count  \\\n",
       "0                 1             0.0          0.00  ...               0.0   \n",
       "1                19           221.0         11.63  ...               3.0   \n",
       "2                -1            -1.0         -1.00  ...               0.0   \n",
       "3                 3           253.0         84.30  ...               0.0   \n",
       "4                -1            -1.0         -1.00  ...               0.0   \n",
       "...             ...             ...           ...  ...               ...   \n",
       "490525           -1            -1.0         -1.00  ...               0.0   \n",
       "490526            1             0.0          0.00  ...               0.0   \n",
       "490527            1             0.0          0.00  ...               0.0   \n",
       "490528           15           254.0         16.94  ...               1.0   \n",
       "490529            4           107.0         26.75  ...               0.0   \n",
       "\n",
       "        month_11.0_count  month_12.0_count  dayofweek_0.0_count  \\\n",
       "0                    0.0               0.0                  2.0   \n",
       "1                    3.0               4.0                  6.0   \n",
       "2                    0.0               0.0                  0.0   \n",
       "3                    0.0               5.0                  0.0   \n",
       "4                    0.0               0.0                  0.0   \n",
       "...                  ...               ...                  ...   \n",
       "490525               0.0               0.0                  0.0   \n",
       "490526               0.0               0.0                  0.0   \n",
       "490527               0.0               0.0                  1.0   \n",
       "490528               3.0               7.0                  0.0   \n",
       "490529               0.0               2.0                  0.0   \n",
       "\n",
       "        dayofweek_1.0_count  dayofweek_2.0_count  dayofweek_3.0_count  \\\n",
       "0                       0.0                  0.0                  0.0   \n",
       "1                      11.0                 11.0                  3.0   \n",
       "2                       0.0                  0.0                  0.0   \n",
       "3                       0.0                  0.0                  0.0   \n",
       "4                       0.0                  0.0                  0.0   \n",
       "...                     ...                  ...                  ...   \n",
       "490525                  0.0                  0.0                  0.0   \n",
       "490526                  1.0                  0.0                  0.0   \n",
       "490527                  0.0                  0.0                  0.0   \n",
       "490528                  3.0                  2.0                  3.0   \n",
       "490529                  0.0                  9.0                  0.0   \n",
       "\n",
       "        dayofweek_4.0_count  dayofweek_5.0_count  dayofweek_6.0_count  \n",
       "0                       0.0                  0.0                  0.0  \n",
       "1                      14.0                  0.0                  3.0  \n",
       "2                       0.0                  0.0                  0.0  \n",
       "3                       1.0                  9.0                  0.0  \n",
       "4                       0.0                  0.0                  0.0  \n",
       "...                     ...                  ...                  ...  \n",
       "490525                  0.0                  0.0                  0.0  \n",
       "490526                  0.0                  0.0                  0.0  \n",
       "490527                  0.0                  0.0                  0.0  \n",
       "490528                  3.0                 16.0                 12.0  \n",
       "490529                  2.0                  0.0                  5.0  \n",
       "\n",
       "[490530 rows x 46 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.drop('label',axis=1)\n",
    "y = train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\tvalid_0's auc: 0.905412\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's auc: 0.905697\n"
     ]
    }
   ],
   "source": [
    "# 划分训练数据集，并进行训练\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=88)\n",
    "train_set = lgb.Dataset(x_train,y_train)\n",
    "val_set = lgb.Dataset(x_val,y_val)\n",
    "\n",
    "callbacks = [callback.log_evaluation(period=1000,show_stdv=True),\n",
    "            callback.early_stopping(stopping_rounds=200)]\n",
    "\n",
    "param = {\n",
    "        'objective':'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate':0.02,\n",
    "        'tree_learner':'serial',\n",
    "        'metric':'auc',\n",
    "        'max_depth':-1,\n",
    "        'num_leaves':31,\n",
    "        'reg_alpha':0,\n",
    "        'reg_lambda':0,\n",
    "        'subsample':0.9,\n",
    "        'colsample_bytree':0.9,\n",
    "        'random_seed':88,\n",
    "        'silent':True,\n",
    "        'verbose':-1, \n",
    "        }\n",
    "model = lgb.train(param,train_set,num_boost_round=20000,valid_sets=val_set,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测评估，绘制roc曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未调参前lgbm单模型在验证集上的AUC：0.9056971055577325\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_pred = model.predict(x_val,num_iteration=model.best_iteration)\n",
    "fpr,tpr,threshold = roc_curve(y_val,val_pred)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print('未调参前lgbm单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Validation ROC')\n",
    "plt.plot(fpr,tpr,'b',label='Val AUC = %0.4f' % roc_auc)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用5折交叉验证进行模型性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm fold 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\tvalid_0's auc: 0.903219\n",
      "Early stopping, best iteration is:\n",
      "[1183]\tvalid_0's auc: 0.903284\n",
      "[0.9048278076385762]\n",
      "lgbm fold 2\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\tvalid_0's auc: 0.902094\n",
      "Early stopping, best iteration is:\n",
      "[1548]\tvalid_0's auc: 0.902357\n",
      "[0.9048278076385762, 0.9406348737039083]\n",
      "lgbm fold 3\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\tvalid_0's auc: 0.905325\n",
      "Early stopping, best iteration is:\n",
      "[1258]\tvalid_0's auc: 0.905438\n",
      "[0.9048278076385762, 0.9406348737039083, 0.9347611334191852]\n",
      "lgbm auc_list:[0.9048278076385762, 0.9406348737039083, 0.9347611334191852]\n",
      "lgbm auc_mean:0.92674127\n",
      "lgbm auc_std:0.01567961\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=3,shuffle=True,random_state=88)\n",
    "prediction_lgbm = np.zeros(len(test_data))\n",
    "auc_cv = []\n",
    "\n",
    "callbacks = [callback.log_evaluation(period=1000,show_stdv=True),\n",
    "             callback.early_stopping(stopping_rounds=200)]  \n",
    "\n",
    "for fold,(train_idx,val_idx) in enumerate(folds.split(x,y)):\n",
    "    print('lgbm fold {}'.format(fold + 1))\n",
    "    train_set = lgb.Dataset(x.iloc[train_idx],y.iloc[train_idx])\n",
    "    val_set = lgb.Dataset(x.iloc[val_idx],y.iloc[val_idx])\n",
    "    \n",
    "    param = {\n",
    "            'objective':'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate':0.02,\n",
    "            'tree_learner':'serial',\n",
    "            'metric':'auc',\n",
    "            'max_depth':-1,\n",
    "            'num_leaves':31,\n",
    "            'reg_alpha':0,\n",
    "            'reg_lambda':0,\n",
    "            'subsample':0.9,\n",
    "            'colsample_bytree':0.9,\n",
    "            'random_seed':88,\n",
    "            'silent':True,\n",
    "            'verbose':-1, \n",
    "            }\n",
    "    model = lgb.train(param,train_set,num_boost_round=20000,valid_sets=val_set,callbacks=callbacks)\n",
    "    val_pred = model.predict(x_val,num_iteration=model.best_iteration)\n",
    "    auc_cv.append(roc_auc_score(y_val,val_pred))\n",
    "    print(auc_cv)\n",
    "\n",
    "print('lgbm auc_list:{}'.format(auc_cv))\n",
    "print('lgbm auc_mean:{:<8.8f}'.format(np.mean(auc_cv)))\n",
    "print('lgbm auc_std:{:<8.8f}'.format(np.std(auc_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgbm =  model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm = pd.DataFrame()\n",
    "result_lgbm['pid'] = test_df.pid\n",
    "result_lgbm['label'] = prediction_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm['label'] = result_lgbm['label'].apply(lambda x:1 if x>0.5 else 0)\n",
    "result_lgbm.to_csv(path + 'result/lgbm_pred_30.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.919616\n",
       "1    0.080384\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lgbm['label'].value_counts()/len(result_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型调参：网络搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1)\n",
    "param_1 = {'max_depth':[3,5,6,7,8,10,12,15]}\n",
    "gsearch_1 = GridSearchCV(estimator=lgb_clf,param_grid=param_1,scoring='roc_auc',cv=5)\n",
    "gsearch_1.fit(X,y)\n",
    "print(gsearch_1.best_params_,gsearch_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',max_depth=6,random_state=42,verbose=-1)\n",
    "param_2 = {'min_child_weight':range(100,150,5)}\n",
    "gsearch_2 = GridSearchCV(estimator=lgb_clf,param_grid=param_2,scoring='roc_auc',cv=5)\n",
    "gsearch_2.fit(X,y)\n",
    "print(gsearch_2.best_params_,gsearch_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1,\n",
    "                        max_depth=6,min_child_weight=140)\n",
    "param_3 = {'learning_rate':[i*0.01 for i in range(0,30,2)]}\n",
    "gsearch_3 = GridSearchCV(estimator=lgb_clf,param_grid=param_3,scoring='roc_auc',cv=5)\n",
    "gsearch_3.fit(X,y)\n",
    "print(gsearch_3.best_params_,gsearch_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1,\n",
    "                        max_depth=6,min_child_weight=140,learning_rate=0.1)\n",
    "param_4 = {'colsample_bytree':[0.6,0.7,0.8,0.9,1]}\n",
    "gsearch_4 = GridSearchCV(estimator=lgb_clf,param_grid=param_4,scoring='roc_auc',cv=5)\n",
    "gsearch_4.fit(X,y)\n",
    "print(gsearch_4.best_params_,gsearch_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1,\n",
    "                        max_depth=6,min_child_weight=140,learning_rate=0.1,\n",
    "                        colsample_bytree=0.6)\n",
    "param_5 = {'subsample':[0.6,0.7,0.8,0.9,1]}\n",
    "gsearch_5 = GridSearchCV(estimator=lgb_clf,param_grid=param_5,scoring='roc_auc',cv=5)\n",
    "gsearch_5.fit(X,y)\n",
    "print(gsearch_5.best_params_,gsearch_5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1,\n",
    "                        max_depth=6,min_child_weight=140,learning_rate=0.1,\n",
    "                        colsample_bytree=0.6,subsample=0.6)\n",
    "param_6= {'reg_alpha':[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    "gsearch_6 = GridSearchCV(estimator=lgb_clf,param_grid=param_6,scoring='roc_auc',cv=5)\n",
    "gsearch_6.fit(X,y)\n",
    "print(gsearch_6.best_params_,gsearch_6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(objective='binary',boosting_typ='gbdt',random_state=42,verbose=-1,\n",
    "                        max_depth=6,min_child_weight=140,learning_rate=0.1,n_estimators=100,\n",
    "                        colsample_bytree=0.6,subsample=0.6,reg_alpha=1)\n",
    "param_7= {'reg_lambda':[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    "gsearch_7 = GridSearchCV(estimator=lgb_clf,param_grid=param_7,scoring='roc_auc',cv=5)\n",
    "gsearch_7.fit(X,y)\n",
    "print(gsearch_7.best_params_,gsearch_7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型调参：贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 定义优化函数\n",
    "def rf_cv_lgb(num_leaves,max_depth,min_child_samples,min_split_gain,\n",
    "              subsample,subsample_freq,colsample_bytree,reg_alpha,reg_lambda):\n",
    "    \n",
    "    model_lgb = lgb.LGBMClassifier(\n",
    "                  objective='binary',\n",
    "                  boosting_type= 'gbdt',\n",
    "                  metric='auc',\n",
    "                  learning_rate=0.1,\n",
    "                  n_estimators=50000,\n",
    "                  num_leaves=int(num_leaves),\n",
    "                  max_depth=int(max_depth),\n",
    "                  min_child_samples=int(min_child_samples),\n",
    "                  min_split_gain=min_split_gain,\n",
    "                  subsample=subsample,\n",
    "                  subsample_freq=int(subsample_freq),\n",
    "                  colsample_bytree=colsample_bytree,\n",
    "                  reg_alpha=reg_alpha,\n",
    "                  reg_lambda=reg_lambda\n",
    "                 )\n",
    "\n",
    "    val_auc = cross_val_score(model_lgb,train_set,val_set,cv=5,scoring='roc_auc').mean()\n",
    "    return val_auc\n",
    "\n",
    "# 定义优化参数\n",
    "bayes_lgb = BayesianOptimization(rf_cv_lgb,\n",
    "                            {\n",
    "                            'num_leaves':(10,150),\n",
    "                            'max_depth':(3,20),    \n",
    "                            'min_child_samples':(10,100),\n",
    "                            'min_split_gain':(0.0,1.0),\n",
    "                            'subsample_freq':(0,100),\n",
    "                            'subsample':(0.5,1.0),\n",
    "                            'colsample_bytree':(0.5,1.0),\n",
    "                            'reg_alpha':(0.0,10),\n",
    "                            'reg_lambda':(0.0,10)\n",
    "                            })\n",
    "\n",
    "bayes_lgb.maximize(n_iter=10)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示优化结果\n",
    "bayes_lgb.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型调参：hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,Trials,fmin,tpe\n",
    "hyper_space = {\n",
    "#     'n_estimators':hp.quniform('n_estimators',100,10000,1),\n",
    "#     'learning_rate':hp.loguniform('learning_rate',np.log(0.05),np.log(0.5)),\n",
    "    'max_depth':hp.quniform('max_depth',3,15,1),\n",
    "    'num_leaves':hp.quniform('num_leaves',3,130,2),\n",
    "    'subsample':hp.choice('subsample',[0.8,0.9,1.0]),\n",
    "    'colsample_bytree':hp.choice('colsample_bytree',[0.8,0.9,1.0]), \n",
    "#     'min_child_samples':hp.quniform('min_child_samples',10,100,1),\n",
    "#     'min_split_gain':hp.loguniform('min_split_gain',np.log(0.1),np.log(1)),\n",
    "#     'subsample_freq':hp.quniform('subsample_freq',1,100,1),\n",
    "    'reg_lambda':hp.loguniform('reg_lambda',np.log(0.01),np.log(1000)),\n",
    "    'reg_alpha':hp.loguniform('reg_alpha',np.log(0.01),np.log(1000))}\n",
    "\n",
    "\n",
    "# 定义优化函数，即五折交叉验证的得分\n",
    "def objective(params,n_folds=5):\n",
    "\n",
    "    num_leaves=int(params['num_leaves'])\n",
    "    max_depth=int(params['max_depth'])\n",
    "#     min_child_samples=int(params.min_child_samples)\n",
    "#     min_split_gain=params.min_split_gain\n",
    "#     subsample_freq=int(params.subsample_freq)\n",
    "    subsample=params['subsample']\n",
    "    colsample_bytree=params['colsample_bytree']\n",
    "    reg_alpha=params['reg_alpha']\n",
    "    reg_lambda=params['reg_lambda']\n",
    "    \n",
    "    callbacks = [callback.log_evaluation(period=1000,show_stdv=True),\n",
    "     callback.early_stopping(stopping_rounds=100)]  \n",
    "    \n",
    "    lgbm_clf = LGBMClassifier(objective='binary',\n",
    "                              boosting_type= 'gbdt',\n",
    "                              metric='auc',\n",
    "                              learning_rate=0.1,\n",
    "                              n_estimators=5000,\n",
    "                              num_leaves=num_leaves,\n",
    "                              max_depth=max_depth,\n",
    "                              subsample=subsample,\n",
    "                              colsample_bytree=colsample_bytree,\n",
    "                              reg_alpha=reg_alpha,\n",
    "                              reg_lambda=reg_lambda,\n",
    "                              is_unbalance=True,\n",
    "                              verbose=-1,   \n",
    "                              random_seed=88)\n",
    "    lgbm_clf.fit(x,y,callbacks=callbacks)\n",
    "    scores = cross_val_score(lgbm_clf,x,y,cv=n_folds,scoring='roc_auc').mean()\n",
    "    return scores\n",
    "\n",
    "\n",
    "# 寻找使优化函数最小超参数组合，利用hyperopt中的fmin来求最小化\n",
    "best = fmin(fn = objective,space=hyper_space,algo=tpe.suggest,max_evals=500)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(model,X,y,test,cat_cols):\n",
    "    n_folds = 5\n",
    "    sk=StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=42)\n",
    "    \n",
    "    pred_test = np.zeros(len(test)) \n",
    "    auc_train,auc_val = 0,0\n",
    "\n",
    "    callbacks = [callback.log_evaluation(period=1000,show_stdv=True),\n",
    "         callback.early_stopping(stopping_rounds=100)]  \n",
    "    \n",
    "    for fold,(train_idx,val_idx) in enumerate(sk.split(X,y)):\n",
    "        print('lgbm fold {}'.format(fold + 1))\n",
    "        x_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        x_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(x_train,y_train,\n",
    "                 eval_set=[(x_val,y_val)],\n",
    "                 categorical_feature = cat_cols,\n",
    "                 callbacks=callbacks)      \n",
    "        \n",
    "        pred_val = model.predict(x_val)\n",
    "        auc_val += roc_auc_score(pred_val,y_val)/sk.n_splits\n",
    "        \n",
    "        pred_test +=  model.predict_proba(test)[:,1]/sk.n_splits\n",
    "\n",
    "    return auc_val,pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(\n",
    "                         objective='binary',\n",
    "                         boosting_type= 'gbdt',\n",
    "                         n_estimators=10000,\n",
    "                         learning_rate=0.1,\n",
    "                         min_child_weight=140,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=31,\n",
    "                         reg_alpha=1,\n",
    "                         reg_lambda=0.2,\n",
    "                         subsample=0.6,\n",
    "                         colsample_bytree=0.6,\n",
    "                         metric='auc',\n",
    "                         verbose=-1,   \n",
    "                         random_seed=42)\n",
    "\n",
    "score,prediction = k_folds(lgbm_clf,X,y,test,cat_features)\n",
    "\n",
    "print('lgbm auc:{:<8.8f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm = pd.DataFrame()\n",
    "result_lgbm['id'] = test_data['id']\n",
    "result_lgbm['isDefault'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm.to_csv('./result/result_lgbm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model(x,y,test):\n",
    "    param = {\n",
    "            'objective':'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate':0.02,\n",
    "            'tree_learner':'serial',\n",
    "            'metric':'auc',\n",
    "            'max_depth':-1,\n",
    "            'num_leaves':31,\n",
    "            'reg_alpha':0,\n",
    "            'reg_lambda':0,\n",
    "            'subsample':0.9,\n",
    "            'colsample_bytree':0.9,\n",
    "            'random_seed':88,\n",
    "            'silent':True,\n",
    "            'verbose':-1, \n",
    "            }\n",
    "    folds = KFold(n_splits=3,shuffle=True,random_state=88)\n",
    "    prediction = np.zeros(len(test_tree))\n",
    "    auc_lgbm = 0\n",
    "    \n",
    "    callbacks = [callback.log_evaluation(period=1000,show_stdv=True),\n",
    "                 callback.early_stopping(stopping_rounds=200)]            \n",
    "    \n",
    "    for fold,(train_idx,val_idx) in enumerate(folds.split(x,y)):\n",
    "        print('lgbm fold {}'.format(fold + 1))\n",
    "        train_set = lgb.Dataset(x.iloc[train_idx],y.iloc[train_idx])\n",
    "        val_set = lgb.Dataset(x.iloc[val_idx],y.iloc[val_idx])\n",
    "        \n",
    "        lgbm_clf = lgb.train(param,train_set,num_boost_round=20000,valid_sets=[train_set,val_set],callbacks=callbacks)\n",
    "        \n",
    "        oof_lgbm[val_idx] = lgbm_clf.predict(X_tree.iloc[val_idx],num_iteration=lgbm_clf.best_iteration)          \n",
    "        auc_val = roc_auc_score(y_tree.iloc[val_idx],oof_lgbm)\n",
    "        prediction += lgbm_clf.predict(test,num_iteration=lgbm_clf.best_iteration) / folds.n_splits \n",
    "    auc_lgbm = roc_auc_score(oof_lgbm,y_tree)\n",
    "    print('lgbm auc:{:<8.8f}'.format(auc_lgbm))  \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
